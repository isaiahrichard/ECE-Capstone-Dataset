{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DEx Basics Notebook\n",
        "Welcome to this notebook! Here, we will explore the functionalities of the tool we are building. Although some parts of this notebook may not be executable directly due to data availability (as the data may reside locally), this notebook aims to provide a comprehensive guide on how to configure and use the different options available in our tool.\n",
        "\n",
        "This notebook will guide you through the process of setting up the `config.json` for the **DEx tool**, allowing you to export datasets according to your specific requirements. We will demonstrate how to manipulate various settings to obtain data structures and formats that best suit your needs.\n",
        "\n",
        "Please note that while some sections may require adjustments based on your local setup, the overall process and configurations remain the same. We hope this notebook serves as a valuable resource in understanding and utilizing the DEx tool effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INFr4cb2UeCb"
      },
      "source": [
        "## Prepare enviroment\n",
        "\n",
        "First, we need the project code. It has to be downloaded from the GitHub repository:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ-M1pRLRla1",
        "outputId": "6a6800ea-04de-4d40-d879-f57ef659a7f5"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Vicomtech/DMD-Driver-Monitoring-Dataset.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we start, it's important to ensure that we have all the necessary libraries installed. Here's a list of the libraries that we'll be using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade opencv-python==4.2.0\n",
        "!pip install --upgrade vcd==6.0\n",
        "!pip install ffmpeg\n",
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: It’s a good practice to use a virtual environment for your projects to avoid conflicts between package versions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Structure of the DMD\n",
        "The DMD is structured into various groups of persons, namely gA, gB, gC, gE, gF, and gZ. Each group typically consists of five people, each represented by a numbered subfolder, with the exception of group gZ, which contains seven individuals. The dataset is further divided into different sessions based on the type of data:\n",
        "\n",
        "- The distraction dataset consists of four sessions: s1, s2, s3, and s4.\n",
        "- The drowsiness dataset consists of one session: s5.\n",
        "- The gaze dataset consists of one session: s6.\n",
        "\n",
        "Each session contains at least one video in RGB, IR, and depth format for each of the cameras (face, body, and hands).  Lastly, there is a .json file that contains the annotations in OpenLABEL format. These annotations are used for DEx to use its functionalities.\n",
        "\n",
        "Next, you can see a representation of the structure of the DMD:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "dmd\n",
        "├───gA\n",
        "│   ├───1\n",
        "│   │   ├───s1\n",
        "│   │   │   ├───gA_1_s1_2019-03-08T09;31;15+01;00_rgb_ann_distraction.json\n",
        "│   │   │   ├───gA_1_s1_2019-03-08T09;31;15+01;00_rgb_face.mp4\n",
        "│   │   │   ├───*.mp4\n",
        "│   │   │   └───*.avi\n",
        "│   │   ├───s2\n",
        "│   │   │   └───...\n",
        "│   │   └───...\n",
        "│   ├───2\n",
        "│   │   └───...\n",
        "│   └───...\n",
        "├───gB\n",
        "│   └───...\n",
        "└───...\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: The .json file has to be in the same folder as its corresponding video. DEx tool can be used to export material that does not belong to the DMD and has been annotated with TaTo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuring DEx tool\n",
        "The DEx tool is highly customizable and allows you to export data according to your specific requirements. This customization is achieved through the `config_DEx.json` file, which contains various variables that you can modify. Here's an example of what it might look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "    \"material\": [\"image\"],\n",
        "    \"streams\" : [\"face\"],\n",
        "    \"channels\" : [\"rgb\"],\n",
        "    \"annotations\" : [\"driver_actions/safe_drive\", \"driver_actions/texting_right\"],\n",
        "    \"write\" : true,\n",
        "    \"size\" : [224, 224],\n",
        "    \"intervalChunk\" : 0,\n",
        "    \"ignoreSmall\" : false,\n",
        "    \"asc\" : true\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is an explanation of all of the available options in the configDEx.json:\n",
        "\n",
        "- @material: list of data format you wish to export. Possible values: \"image\", \"video\".\n",
        "\n",
        "- @streams: list of camera names to export material from. Possible values: \"face\", \"body\", \"hands\", and \"general\" (\"general\" if not DMD material).\n",
        "\n",
        "- @channels: list of channels of information you wish to export. Possible values: \"RGB\", \"IR\", and \"depth\".\n",
        "\n",
        "- @annotations: list of classes you wish to export (e.g. [\"safe_drive\", \"drinking\"], or \"all\"). Possible values: all label names or only all. The name written can be the type name like in OpenLABEL (e.g.,\"driver_actions/safe_drive\"), or just the label name (e.g.,\"safe_drive\"). You can find the specific name of the name in OpenLABEL format in the .json file or using the mode to get statistics of the DMD. Except for objects (cell phone, hair comb, and bottle) that have to be with the \"object_in_scene/__\" label. Also, the name of the action can be its uid number (e.g. [0,1,2]), but be aware that uid might not be the same in all OpenLabel.\n",
        "\n",
        "- @write: Flag to create/write material in the destination folder (True) or just get the intervals (False). Possible values: True, False.\n",
        "\n",
        "The following options are not necessary to be in the config file, if you don't put them, they will take the default value assigned:\n",
        "\n",
        "- @size: the size of the final output (images or videos). Set it as \"original\" or a tuple with a smaller size than the original (width, height). e.g.(224,224). The default value is (224, 244).\n",
        "\n",
        "- @intervalChunk: the size of divisions you wish to do to the frame intervals (in case you want videos of x frames each). Possible values: Number greater than 1. The default value is 0, meaning this option is deactivated.\n",
        "\n",
        "- @ignoreSmall: True to ignore intervals that cannot be cut because they are smaller than @intervalChunk. Possible values: True or False. The default value is deactivated.\n",
        "\n",
        "- @asc: When cutting interval chunks, the value should be true to create the intervals going in ascendant order (in a video of 105 frames taking chunks of 50 frames DEx creates [0-49, 50-99, 100-104] intervals). The value should be false to go in descendent order (With the 105 frames video taking chunks of 50 frames the intervals created will be [55-104, 5-54, 0-4]). Possible values: True or False. The default value is true, acting as ascendant order.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Excecuting DEx Tool\n",
        "\n",
        "To execute the tool, do it like this: \n",
        "\n",
        "**NOTE**: You must execute the DExTool inside `./DMD-Driver-Monitoring-Dataset/exploreMaterial-tool/`, otherwise it will not find the `config_DEx.json`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "python DExTool.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After excecuting DEx, it will show you 4 functionalities. \n",
        "- 0: export material for training\n",
        "- 1: group exported material by classes\n",
        "- 2: create train and test split\n",
        "- 3: get statistics\n",
        "\n",
        "Press the corresponding number on the keyboard to select the option.\n",
        "\n",
        "**NOTE:** Option 0, 1 and 2, must be excecuted in that order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Welcome :)\n",
        "What do you whish to do?:  export material for training:[0]  group exported material by classes:[1]  create train and test split:[2]  get statistics:[3] : 0\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example of some use cases\n",
        "Next, there are some use cases to illustrate how to configure the `config_DEx.json` file for different scenarios. Whether you're interested in exporting RGB images for safe driving actions or IR videos for drinking actions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Exporting IR images of face camera of safe_drive action\n",
        "In this use case, DEx is going to get the images of the distraction dataset in DMD from the face camera when the driver is driving safely. Here you can see how config_DEx.json should be (The options not listed take the default value):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "    \"material\": [\"image\"],\n",
        "    \"streams\" : [\"face\"],\n",
        "    \"channels\" : [\"ir\"],\n",
        "    \"annotations\" : [\"driver_actions/safe_drive\"],\n",
        "    \"write\" : true\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you pressed the option \"0\". DEx will ask you for a **destination path** to output the images. \n",
        "\n",
        "Also, you need to specify how you want to **read the annotations**: e.g., Only an OpenLabel, or you want to export the material from a whole group. \n",
        "\n",
        "In this case, we will export the material from Group C. So we put the path to this folder: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Welcome :)\n",
        "What do you whish to do?:  export material for training:[0]  group exported material by classes:[1]  create train and test split:[2]  get statistics:[3] : 0\n",
        "To change export settings go to config_DEx.json and change control variables.\n",
        "Enter destination path: C:\\Users\\example\\Documents\\Output\n",
        "How do you want to read annotations, by: Group:[g]  Sessions:[f]  One OpenLABEL:[v] : g\n",
        "Enter DMD group's path (../dmd/g#): C:\\Users\\example\\Documents\\dmd\\gC\n",
        "Enter the session you wish to export in this group:  all:[0]  S1:[1]  S2:[2]  S3[3]  S4[4] : 1\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\11\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\11\\s1\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\11\\s1\\gC_11_s1_2019-03-04T09;33;18+01;00_rgb_ann_distraction.json\n",
        "There are 13 actions in this OpenLABEL\n",
        "\n",
        "\n",
        "-- Getting data of rgb channel --\n",
        "\n",
        "\n",
        "-- Creating image of action: driver_actions/safe_drive --\n",
        "rgb face stream loaded: gC_11_s1_2019-03-04T09;33;18+01;00_rgb_face.mp4\n",
        "Total frame loss: 0 of total: 3798\n",
        "Resulting number of intervals: 91 from initial number: 28\n",
        "Writing...\n",
        "Directory safe_drive created\n",
        "Oki :) ----------------------------------------\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output will have a structure similar to this one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Output\n",
        "└───dmd_ir\n",
        "    └───s1\n",
        "        └───driver_actions\n",
        "            └───safe_drive\n",
        "                ├───face_2019-03-08-09;31;15_1_0_15.jpg\n",
        "                └───...\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Exporting videos with a minimum of 30 frames of drivers talking\n",
        "In this use case, DEx is going to get videos with a minimum of 30 frames from the distraction dataset in DMD. These videos will correspond to the talking_to_passenger annotation. The config_DEx.json will include every stream and channel to get all the possible videos and the ignoreSmall option will be activated to discard the videos smaller than 30 frames. Here you can see how config_DEx.json should be (The options not listed take the default value):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "    \"material\": [\"video\"],\n",
        "    \"streams\" : [\"face\",\"body\",\"hands\"],\n",
        "    \"channels\" : [\"rgb\",\"ir\",\"depth\"],\n",
        "    \"annotations\" : [\"driver_actions/talking_to_passenger\"],\n",
        "    \"write\" : true,\n",
        "    \"intervalChunk\" : 30,\n",
        "    \"ignoreSmall\" : true\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here you can see an example of execution taking only gA_1_s1_2019-03-08T09;31;15+01;00_rgb_face.mp4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Welcome :)\n",
        "What do you whish to do?:  export material for training:[0]  group exported material by classes:[1]  create train and test split:[2]  get statistics:[3] : 0\n",
        "To change export settings go to config_DEx.json and change control variables.\n",
        "Enter destination path: C:\\Users\\example\\Documents\\Output\n",
        "How do you want to read annotations, by: Group:[g]  Sessions:[f]  One OpenLABEL:[v] : g\n",
        "Enter DMD group's path (../dmd/g#): C:\\Users\\example\\Documents\\dmd\\gA\n",
        "Enter the session you wish to export in this group:  all:[0]  S1:[1]  S2:[2]  S3[3]  S4[4] S5[5] S6[6] : 1\n",
        "C:\\Users\\example\\Documents\\dmd\\gA\\1\n",
        "C:\\Users\\example\\Documents\\dmd\\gA\\1\\s1\n",
        "C:\\Users\\example\\Documents\\dmd\\gA\\1\\s1\\gA_1_s1_2019-03-08T09;31;15+01;00_rgb_ann_distraction.json\n",
        "There are 13 actions in this OpenLABEL\n",
        "\n",
        "\n",
        "-- Getting data of rgb channel --\n",
        "\n",
        "\n",
        "-- Creating video of action: driver_actions/talking_to_passenger --\n",
        "rgb face stream loaded: gA_1_s1_2019-03-08T09;31;15+01;00_rgb_face.mp4\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [2128, 2154] for being too small :(\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [2257, 2274] for being too small :(\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [2408, 2431] for being too small :(\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [2560, 2587] for being too small :(\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [4995, 5021] for being too small :(\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [5203, 5228] for being too small :(\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [5281, 5306] for being too small :(\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [5331, 5357] for being too small :(\n",
        "WARNING: the interval chunk length chosen is too small, some intervals are too small to be cutted by 30 frames. To ignore small intervals, set True to ignoreSmall argument.\n",
        "WARNING: Skipped interval [5478, 5504] for being too small :(\n",
        "Total frame loss: 49 of total: 421\n",
        "Resulting number of intervals: 5 from initial number: 14\n",
        "Writing...\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output of the execution should have a structure similar to this one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Output\n",
        "├───dmd_depth\n",
        "│   └───s1\n",
        "│       └───driver_actions\n",
        "│           └───talking_to_passenger\n",
        "│               ├───body_2019-03-08-09;31;15_1_0.avi\n",
        "│               ├───face_2019-03-08-09;31;15_1_0.avi\n",
        "│               ├───hands_2019-03-08-09;31;15_1_0.avi\n",
        "│               └───...\n",
        "├───dmd_ir\n",
        "│   └───s1\n",
        "│       └───driver_actions\n",
        "│           └───talking_to_passenger\n",
        "│               ├───body_2019-03-08-09;31;15_1_0.avi\n",
        "│               ├───face_2019-03-08-09;31;15_1_0.avi\n",
        "│               ├───hands_2019-03-08-09;31;15_1_0.avi\n",
        "│               └───...\n",
        "└───dmd_rgb\n",
        "    └───s1\n",
        "        └───driver_actions\n",
        "            └───talking_to_passenger\n",
        "                ├───body_2019-03-08-09;31;15_1_0.avi\n",
        "                ├───face_2019-03-08-09;31;15_1_0.avi\n",
        "                ├───hands_2019-03-08-09;31;15_1_0.avi\n",
        "                └───...\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Exporting Depth material in video for gaze zone estimation\n",
        "In this use case, DEx is going to get videos from the gaze dataset in DMD. As we mentioned before, the gaze dataset only contains the session 6 recorded, for this reason when asked by the DEx tool which session to export you have to choose s6 or the all option. In case you choose another session the DEx tool isn't going to return anything because it isn't going to find the videos. Here you can see how config_DEx.json should be (The options not listed take the default value):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "    \"material\": [\"video\"],\n",
        "    \"streams\" : [\"face\"],\n",
        "    \"channels\" : [\"depth\"],\n",
        "    \"annotations\" : \"all\",\n",
        "    \"write\" : true,\n",
        "    \"size\" : \"original\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here you can see an example of execution with these options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Welcome :)\n",
        "What do you whish to do?:  export material for training:[0]  group exported material by classes:[1]  create train and test split:[2]  get statistics:[3] : 0\n",
        "To change export settings go to config_DEx.json and change control variables.\n",
        "Enter destination path: C:\\Users\\example\\Documents\\Output\n",
        "How do you want to read annotations, by: Group:[g]  Sessions:[f]  One OpenLABEL:[v] : g\n",
        "Enter DMD group's path (../dmd/g#): C:\\Users\\example\\Documents\\dmd\\gA\n",
        "Enter the session you wish to export in this group:  all:[0]  S1:[1]  S2:[2]  S3[3]  S4[4] S5[5] S6[6] : 6\n",
        "C:\\Users\\example\\Documents\\dmd\\gA\\1\n",
        "C:\\Users\\example\\Documents\\dmd\\gA\\1\\s6\n",
        "C:\\Users\\example\\Documents\\dmd\\gA\\1\\s6\\gA_1_s6_2019-03-08T09;15;15+01;00_rgb_ann_gaze.json\n",
        "There are 11 actions in this OpenLABEL\n",
        "\n",
        "\n",
        "-- Getting data of depth channel --\n",
        "\n",
        "\n",
        "-- Creating video of action: gaze_zone/left_mirror --\n",
        "depth face stream loaded: gA_1_s6_2019-03-08T09;15;15+01;00_depth_face.avi\n",
        "Writing...\n",
        "Directory left_mirror created\n",
        "ffmpeg version 6.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
        "  built with clang version 17.0.4\n",
        "  configuration: --prefix=/d/bld/ffmpeg_1699837986739/_h_env/Library --cc=clang.exe --cxx=clang++.exe --nm=llvm-nm --ar=llvm-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --ld=lld-link --target-os=win64 --enable-cross-compile --toolchain=msvc --host-cc=clang.exe --extra-libs=ucrt.lib --extra-libs=vcruntime.lib --extra-libs=oldnames.lib --strip=llvm-strip --disable-stripping --host-extralibs= --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/d/bld/ffmpeg_1699837986739/_build_env/Library/bin/pkg-config\n",
        "  libavutil      58. 29.100 / 58. 29.100\n",
        "  libavcodec     60. 31.102 / 60. 31.102\n",
        "  libavformat    60. 16.100 / 60. 16.100\n",
        "  libavdevice    60.  3.100 / 60.  3.100\n",
        "  libavfilter     9. 12.100 /  9. 12.100\n",
        "  libswscale      7.  5.100 /  7.  5.100\n",
        "  libswresample   4. 12.100 /  4. 12.100\n",
        "  libpostproc    57.  3.100 / 57.  3.100\n",
        "Input #0, avi, from '\\\\gpfs-cluster\\activos\\DMD\\gaze-final\\dmd\\gA\\1\\s6\\gA_1_s6_2019-03-08T09;15;15+01;00_depth_face.avi':\n",
        "  Metadata:\n",
        "    software        : Lavf58.29.100\n",
        "  Duration: 00:02:59.44, start: 0.000000, bitrate: 50707 kb/s\n",
        "  Stream #0:0: Video: ffv1 (FFV1 / 0x31564646), gray16le, 1280x720, 50708 kb/s, 29.76 fps, 29.76 tbr, 29.76 tbn\n",
        "[out#0/avi @ 0000026BA49CA9C0] Codec AVOption crf (Select the quality for constant quality mode) has not been used for any stream. The most likely reason is either wrong type (e.g. a video option with no video streams) or that it is a private option of some encoder which was not actually used for any stream.\n",
        "Stream mapping:\n",
        "  Stream #0:0 (ffv1) -> trim:default\n",
        "  setpts:default -> Stream #0:0 (ffv1)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The expected structure of the output of the execution should be similar to this one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Output\n",
        "└───s6\n",
        "    ├───blinks\n",
        "    │   ├───blinking\n",
        "    │   │   ├───face_2019-03-08-09;15;15_1_0.avi\n",
        "    │   │   └───...\n",
        "    │   └───...\n",
        "    ├───gaze_zone\n",
        "    │   ├───center_mirror\n",
        "    │   │   └───...\n",
        "    │   └───...\n",
        "    └───...\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Joining the exported material by classes\n",
        "\n",
        "In case you export more than one session of the DMD using the mode \"export material for training:[0]\", the tool extracts the different actions in folders divided by the sessions. Now we're going to explain the next option that combines the subfolders of different sessions in only one folder to be used in training. Having the following structure of subfolders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "dmd_rgb\n",
        "├───s1\n",
        "│   └───driver_actions\n",
        "│       ├───drinking\n",
        "│       └───radio\n",
        "└───s4\n",
        "    └───driver_actions\n",
        "        ├───drinking\n",
        "│       └───radio\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The execution should go like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Welcome :)\n",
        "What do you whish to do?:  export material for training:[0]  group exported material by classes:[1]  create train and test split:[2]  get statistics:[3] : 1\n",
        "Enter exported DMD material path (inside must be sessions folders(s#) e.g:../dmd_rgb/): C:\\Users\\example\\Documents\\Output\\dmd_rgb\n",
        "dir True\n",
        "Moving drinking to C:\\Users\\example\\Documents\\Output\\dmd_rgb\\driver_actions\\drinking\n",
        "Moving radio to C:\\Users\\example\\Documents\\Output\\dmd_rgb\\driver_actions\\radio\n",
        "dir True\n",
        "Moving drinking to C:\\Users\\example\\Documents\\Output\\dmd_rgb\\driver_actions\\drinking\n",
        "Oki :) ----------------------------------------\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, the structure of folders should be transformed to this one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "dmd_rgb\n",
        "└───driver_actions\n",
        "    ├───drinking\n",
        "    └───radio\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Dividing exported material into train and test splits\n",
        "\n",
        "Once the annotations are separated in folders, you can split the dataset in training and test. To do this, let's assume that we have the structure of folders as shown in last section. With this in mind, the execution should be similar to this one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Welcome :)\n",
        "What do you whish to do?:  export material for training:[0]  group exported material by classes:[1]  create train and test split:[2]  get statistics:[3] : 2\n",
        "This function only works with dmd material structure when exporting with DEx tool.\n",
        "Enter exported material path (inside must be classes folders e.g.: /safe_driving/*.jpg): C:\\Users\\example\\Documents\\OMS\\DEx\\TutorialNotebook\\Salida\\dmd_rgb\\driver_actions\n",
        "Enter destination path (a new folder to store train and test splits): C:\\Users\\example\\Documents\\OMS\\DEx\\TutorialNotebook\\Salida\\split\n",
        "Enter test proportion for split [0-1] (e.g. 0.20): 0.20\n",
        "folders:  ['C:\\Users\\example\\Documents\\Output\\dmd_rgb\\driver_actions\\drinking', 'C:\\Users\\example\\Documents\\Output\\dmd_rgb\\driver_actions\\radio']\n",
        "Moving  164  files:  131  for training and  33  for testing.\n",
        "Moving  126  files:  101  for training and  25  for testing.\n",
        "Oki :) ----------------------------------------\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see in the execution, you have to put the path to the folder containing all the annotations. The structure of the folder should be something similar to this one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "split\n",
        "├───test\n",
        "│   ├───0\n",
        "│   └───1\n",
        "└───train\n",
        "    ├───0\n",
        "    └───1\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, the folders 0 contains videos corresponding with the drinking annotation and the folders 1 contains videos corresponding with the radio annotation.\n",
        "\n",
        "### 6. Getting statistics of annotations\n",
        "\n",
        "This mode gets the statistics of a group, session or one OpenLABEL of the DMD. The result is two files called example-frames.txt and example-actions.txt, being example the name you input to the tool. The example-frames.txt contains the total number of frames, and the example-actions.txt contains the number of frames in which an annotation appears. Let's see an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Welcome :)\n",
        "What do you whish to do?:  export material for training:[0]  group exported material by classes:[1]  create train and test split:[2]  get statistics:[3] : 3\n",
        "This function only works with dmd material structure when exporting with DEx tool.\n",
        "Enter filename for a report file (e.g. report.txt): statisticsDMDc.txt\n",
        "How do you want to read annotations, by: Group:[g]  Sessions:[f]  One OpenLABEL:[v] : g\n",
        "Enter DMD group's path (../dmd/g#): C:\\Users\\example\\Documents\\dmd\\gC\n",
        "Enter the session you wish to export in this group:  all:[0]  S1:[1]  S2:[2]  S3[3]  S4[4] S5[5] S6[6] : 1\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\11\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\11\\s1\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\11\\s1\\gC_11_s1_2019-03-04T09;33;18+01;00_rgb_ann_distraction.json\n",
        "There are 13 actions in this OpenLABEL\n",
        "Oki :) ----------------------------------------\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\12\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\12\\s1\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\12\\s1\\gC_12_s1_2019-03-13T10;23;45+01;00_rgb_ann_distraction.json\n",
        "There are 13 actions in this OpenLABEL\n",
        "Oki :) ----------------------------------------\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\13\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\13\\s1\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\13\\s1\\gC_13_s1_2019-03-04T10;26;12+01;00_rgb_ann_distraction.json\n",
        "There are 13 actions in this OpenLABEL\n",
        "Oki :) ----------------------------------------\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\14\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\14\\s1\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\14\\s1\\gC_14_s1_2019-03-04T11;56;20+01;00_rgb_ann_distraction.json\n",
        "There are 15 actions in this OpenLABEL\n",
        "Oki :) ----------------------------------------\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\15\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\15\\s1\n",
        "C:\\Users\\example\\Documents\\dmd\\gC\\15\\s1\\gC_15_s1_2019-03-04T11;24;57+01;00_rgb_ann_distraction.json\n",
        "There are 12 actions in this OpenLABEL\n",
        "Oki :) ----------------------------------------\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see by the name we have given to the tool, the files that has been created are called statisticsDMDc-frames.txt and statisticsDMDc-actions.txt. An important detail to have in mind is that the name given to the report file has to contain .txt suffix. Here is the content in statisticsDMDc-frames.txt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "total_frames:34636\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Content in statisticsDMDc-actions.txt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "gaze_on_road/looking_road:28683\n",
        "gaze_on_road/not_looking_road:5477\n",
        "talking/talking:5330\n",
        "hands_using_wheel/both:20487\n",
        "hands_using_wheel/only_left:13510\n",
        "hand_on_gear/hand_on_gear:100\n",
        "driver_actions/safe_drive:19344\n",
        "driver_actions/radio:4145\n",
        "driver_actions/drinking:3409\n",
        "driver_actions/reach_side:2730\n",
        "driver_actions/talking_to_passenger:2078\n",
        "driver_actions/unclassified:2562\n",
        "objects_in_scene/bottle:6202\n",
        "hands_using_wheel/none:265\n",
        "hands_using_wheel/only_right:103\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
